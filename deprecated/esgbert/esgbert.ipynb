{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "aUaDz_3_m0L9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchserve\n",
      "  Downloading torchserve-0.4.2-py2.py3-none-any.whl (18.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 18.1 MB 4.9 MB/s eta 0:00:011     |███████████████████████████████▌| 17.8 MB 4.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch-model-archiver\n",
      "  Downloading torch_model_archiver-0.4.2-py2.py3-none-any.whl (14 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.8.0-cp38-cp38-macosx_10_9_x86_64.whl (236 kB)\n",
      "\u001b[K     |████████████████████████████████| 236 kB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "  Downloading future-0.18.2.tar.gz (829 kB)\n",
      "\u001b[K     |████████████████████████████████| 829 kB 16.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Pillow\n",
      "  Downloading Pillow-8.3.2-cp38-cp38-macosx_10_10_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 10.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "  Using cached packaging-21.0-py3-none-any.whl (40 kB)\n",
      "Collecting enum-compat\n",
      "  Downloading enum_compat-0.0.3-py3-none-any.whl (1.3 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=2ff5974a7f6b46bd8fbc6b663b2aef998cde7350a506a97bbf7ae4910b88e23f\n",
      "  Stored in directory: /Users/xinminaw/Library/Caches/pip/wheels/8e/70/28/3d6ccd6e315f65f245da085482a2e1c7d14b90b30f239e2cf4\n",
      "Successfully built future\n",
      "Installing collected packages: pyparsing, psutil, Pillow, packaging, future, enum-compat, torchserve, torch-model-archiver\n",
      "Successfully installed Pillow-8.3.2 enum-compat-0.0.3 future-0.18.2 packaging-21.0 psutil-5.8.0 pyparsing-2.4.7 torch-model-archiver-0.4.2 torchserve-0.4.2\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.10.0-cp38-cp38-macosx_10_9_x86_64.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from torchvision) (1.21.2)\n",
      "Requirement already satisfied: pillow>=5.3.0 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from torchvision) (8.3.2)\n",
      "Collecting torch==1.9.0\n",
      "  Downloading torch-1.9.0-cp38-none-macosx_10_9_x86_64.whl (127.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 127.9 MB 230 kB/s eta 0:00:011    |██████████████████████▍         | 89.5 MB 5.9 MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: typing-extensions, torch, torchvision\n",
      "Successfully installed torch-1.9.0 torchvision-0.10.0 typing-extensions-3.10.0.2\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.10.2-py3-none-any.whl (2.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.8 MB 3.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from transformers) (21.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 12.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from transformers) (1.21.2)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.62.2-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 23.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp38-cp38-macosx_10_9_x86_64.whl (253 kB)\n",
      "\u001b[K     |████████████████████████████████| 253 kB 14.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2021.8.28-cp38-cp38-macosx_10_9_x86_64.whl (285 kB)\n",
      "\u001b[K     |████████████████████████████████| 285 kB 15.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from transformers) (2.26.0)\n",
      "Collecting huggingface-hub>=0.0.12\n",
      "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 9.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-macosx_10_11_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 27.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from huggingface-hub>=0.0.12->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: click in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 7.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/xinminaw/Documents/GitHub/team08-capstone/capstone08/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Installing collected packages: tqdm, regex, joblib, filelock, tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.0.12 huggingface-hub-0.0.17 joblib-1.0.1 pyyaml-5.4.1 regex-2021.8.28 sacremoses-0.0.45 tokenizers-0.10.3 tqdm-4.62.2 transformers-4.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchserve torch-model-archiver\n",
    "!pip install torchvision \n",
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11246,
     "status": "ok",
     "timestamp": 1631630654172,
     "user": {
      "displayName": "Aw Xinmin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06752460833044393240"
     },
     "user_tz": -480
    },
    "id": "LwWkmYtAwtL_",
    "outputId": "a9f7864a-5aee-4d2c-bdb0-f3ef5ccebf91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   155  100   155    0     0    807      0 --:--:-- --:--:-- --:--:--   807\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   520  100   520    0     0   2736      0 --:--:-- --:--:-- --:--:--  2736\n",
      "Update environment...\n",
      "Install Java...\n",
      "Install Jupyter java kernel...\n"
     ]
    }
   ],
   "source": [
    "# Prepare Java Kernel for Google Colab\n",
    "!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/fix-colab-gpu.sh && bash fix-colab-gpu.sh\n",
    "!curl -O https://raw.githubusercontent.com/deepjavalibrary/d2l-java/master/tools/colab_build.sh && bash colab_build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 29406,
     "status": "ok",
     "timestamp": 1631632986805,
     "user": {
      "displayName": "Aw Xinmin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06752460833044393240"
     },
     "user_tz": -480
    },
    "id": "epf-Y3B-poPa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR - /Users/xinminaw/Documents/GitHub/team08-capstone/ESG BERT/bert.mar already exists.\r\n",
      "Please specify --force/-f option to overwrite the model archive output file.\r\n",
      "See -h/--help for more details.\r\n"
     ]
    }
   ],
   "source": [
    "! torch-model-archiver --model-name \"bert\" --version 1.0 --serialized-file \"bert_model/pytorch_model.bin\" --extra-files \"bert_model/config.json,bert_model/vocab.txt\" --handler \"bert_model/handler.py\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1631632986806,
     "user": {
      "displayName": "Aw Xinmin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06752460833044393240"
     },
     "user_tz": -480
    },
    "id": "TLXl9a0drjkt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: model_store: File exists\r\n"
     ]
    }
   ],
   "source": [
    "! mkdir model_store && mv bert.mar model_store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12492,
     "status": "ok",
     "timestamp": 1631632999279,
     "user": {
      "displayName": "Aw Xinmin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06752460833044393240"
     },
     "user_tz": -480
    },
    "id": "AzqAgzkjuvI6",
    "outputId": "1a080c2c-f73f-49d1-d9b2-6a78b4bced71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing orphan pid file.\r\n"
     ]
    }
   ],
   "source": [
    "! torchserve --start --model-store model_store --models bert=bert.mar --ts-config config.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1631632999750,
     "user": {
      "displayName": "Aw Xinmin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06752460833044393240"
     },
     "user_tz": -480
    },
    "id": "SvzvuB0WvVNN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl: (7) Failed to connect to localhost port 8080: Connection refused\r\n"
     ]
    }
   ],
   "source": [
    "! curl -X POST http://localhost:8080/predictions/bert -T \"bert_model/predict.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1631632956172,
     "user": {
      "displayName": "Aw Xinmin",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "06752460833044393240"
     },
     "user_tz": -480
    },
    "id": "jUOac6HTwcGx",
    "outputId": "a772a2f8-edff-41ae-a6c7-fb7ae68391d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchServe has stopped.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! torchserve --stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_IPFKWEvJVR"
   },
   "source": [
    "# New section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNV/uyk/neXHxuhl4LWt5zG",
   "collapsed_sections": [],
   "mount_file_id": "1iHLi4ZxKBurNa8OVxTykuPPDKmnmGc5q",
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
