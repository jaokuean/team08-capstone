{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4AbYWwPirPV"
   },
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Xbp-Xa1hcbq",
    "outputId": "b96f2088-3f8f-4c9b-9852-b223cefcd987"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "z7VqWBsChVNa"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/labelled_data/all_labelled_17Oct.csv\" \n",
    "data = pd.read_csv(DATA_PATH)\n",
    "data.columns = ['index', 'sentence', 'relevance', 'carbon_class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mo6X1pYw-LRi",
    "outputId": "0c6994c5-aba6-45d1-d569-b7c22356dd05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4775\n",
       "1     464\n",
       "Name: relevance, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5NwaJjtxm3G"
   },
   "source": [
    "### Preprocess text before BERT creating word emeddings \n",
    "1. ONLY remove all punctuations except except %,$,&\n",
    "\n",
    "1. DO NOT remove numbers because we want to capture numbers\n",
    "2. DO NOT lemmatize/lowercase etc because BERT does not require it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIenLl1bfjCd"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(string):\n",
    "    return ''.join(i for i in string if not i.isdigit())\n",
    "\n",
    "def remove_punc(s):\n",
    "    import string\n",
    "    exclude = string.punctuation\n",
    "    final_punc = ''.join(list(i for i in exclude if i not in ['%', '$', '&']))\n",
    "    s = ''.join(ch for ch in s if ch not in list(final_punc))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPFcItwjxggZ"
   },
   "outputs": [],
   "source": [
    "data.sentence = data.sentence.map(remove_punc)\n",
    "#data = data.loc[data.carbon_class.notnull()] # comment out for relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6ew1hCZ-lfYA"
   },
   "outputs": [],
   "source": [
    "train, val, test = \\\n",
    "              np.split(data.sample(frac=1, random_state=4103), \n",
    "                       [int(.6*len(data)), int(.8*len(data))])\n",
    "trainval =pd.concat([train, val])\n",
    "labels = [train.relevance, val.relevance, test.relevance, trainval.relevance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.899809\n",
       "1    0.100191\n",
       "Name: relevance, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.relevance.value_counts() / (943+105)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMILMqNvrb04"
   },
   "source": [
    "### BERT embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vt-cwriBrKcU",
    "outputId": "ba5faeaa-5a4c-400a-9274-ea2d13d9574a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "!pip install bert-serving-client\n",
    "!pip install -U bert-serving-server[http]\n",
    "\n",
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip uncased_L-12_H-768_A-12.zip\n",
    "!nohup bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 > out.file 2>&1 &\n",
    "\n",
    "\n",
    "!ls  # you should see uncased_something_.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66N4AACr1uGs"
   },
   "outputs": [],
   "source": [
    "vect_methods = {'type': ['bert_as_a_service']}\n",
    "vect_methods_paramgrid = list(ParameterGrid(vect_methods))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRVrf6V1zAoI"
   },
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vKIozCseFNW"
   },
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "logreg_params = { \"C\": [0.1, 0.5, 1.0, 1.5, 5], \n",
    "                 \"solver\": [\"lbfgs\", \"newton-cg\"], \n",
    "                 \"penalty\": [\"l2\", \"none\"],\n",
    "                 \"class_weight\": [\"balanced\", None]}\n",
    "logreg_paramgrid = list(ParameterGrid(logreg_params))\n",
    "\n",
    "\n",
    "# svm\n",
    "svm_params = { \"C\": [0.1, 0.5, 1.0, 1.5, 5],\n",
    "    \"kernel\": [\"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"class_weight\": [\"balanced\", None] \n",
    "}\n",
    "\n",
    "svm_paramgrid = list(ParameterGrid(svm_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXeNZzh6tl_l"
   },
   "outputs": [],
   "source": [
    "#Oversampling the data\n",
    "def oversample_ros(X,y):\n",
    "    ros = RandomOverSampler(random_state = 4103,sampling_strategy=1.0)\n",
    "    # label encode the target variable\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "    return X,y\n",
    "\n",
    "def oversample_smote(X,y):\n",
    "    smote = SMOTE(random_state = 4103)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEB-0Vc2qgzo"
   },
   "outputs": [],
   "source": [
    "def vectorize_dataset_ros():\n",
    "    # BERT as a Service\n",
    "    from bert_serving.client import BertClient\n",
    "    bc = BertClient(check_length=False)\n",
    "\n",
    "    bert_train = bc.encode(list(train.sentence))\n",
    "    bert_val = bc.encode(list(val.sentence))\n",
    "    bert_test = bc.encode(list(test.sentence))\n",
    "    bert_trainval = bc.encode(list(trainval.sentence))\n",
    "    \n",
    "    # oversample minority class\n",
    "    bert_train_oversampled = oversample_ros(bert_train, labels[0])\n",
    "    bert_trainval_oversampled = oversample_ros(bert_trainval, labels[3])\n",
    "    \n",
    "    return {'bert_as_a_service': [bert_train_oversampled, bert_val, bert_test, bert_trainval_oversampled]}\n",
    "\n",
    "\n",
    "def vectorize_dataset_smote():\n",
    "    # BERT as a Service\n",
    "    from bert_serving.client import BertClient\n",
    "    bc = BertClient(check_length=False)\n",
    "\n",
    "    bert_train = bc.encode(list(train.sentence))\n",
    "    bert_val = bc.encode(list(val.sentence))\n",
    "    bert_test = bc.encode(list(test.sentence))\n",
    "    bert_trainval = bc.encode(list(trainval.sentence))\n",
    "    \n",
    "    # oversample minority class\n",
    "    bert_train_oversampled = oversample_smote(bert_train, labels[0])\n",
    "    bert_trainval_oversampled = oversample_smote(bert_trainval, labels[3])\n",
    "    \n",
    "    return {'bert_as_a_service': [bert_train_oversampled, bert_val, bert_test, bert_trainval_oversampled]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0AkjdoAq0gx"
   },
   "outputs": [],
   "source": [
    "def hyperparam_search(dataset,model, model_function, model_grid):\n",
    "    ind = 0 \n",
    "    gridsearch_results = []\n",
    "    dataset = dataset\n",
    "    for vect_choice in vect_methods_paramgrid:\n",
    "        vect = vect_choice['type']\n",
    "        train_hp = dataset[vect][0][0]\n",
    "        val_hp = dataset[vect][1]\n",
    "        test_hp = dataset[vect][2]\n",
    "        trainval_hp = dataset[vect][3][0]\n",
    "\n",
    "        train_label = dataset[vect][0][1]\n",
    "        val_label = labels[1]\n",
    "        test_label = labels[2]\n",
    "        trainval_label = dataset[vect][3][1]\n",
    "\n",
    "        for model_param in model_grid:\n",
    "            # fit model on train set\n",
    "            model = model_function(**model_param)\n",
    "            model.fit(train_hp, train_label)\n",
    "            val_pred = model.predict(val_hp)\n",
    "\n",
    "            # scoring\n",
    "            val_metrics = classification_report(val_label, val_pred, output_dict=True)\n",
    "            val_accuracy = val_metrics[\"accuracy\"]\n",
    "            val_f1_weighted = val_metrics[\"weighted avg\"][\"f1-score\"]\n",
    "            val_f1_zero = val_metrics[\"0\"][\"f1-score\"]\n",
    "            val_f1_one = val_metrics[\"1\"][\"f1-score\"]\n",
    "\n",
    "            # fit model on trainval set\n",
    "            model = model_function(**model_param)\n",
    "            model.fit(trainval_hp, trainval_label)\n",
    "            test_pred = model.predict(test_hp)\n",
    "\n",
    "            # scoring\n",
    "            test_metrics = classification_report(test_label, test_pred, output_dict=True)\n",
    "            test_accuracy = test_metrics[\"accuracy\"]\n",
    "            test_f1_weighted = test_metrics[\"weighted avg\"][\"f1-score\"]\n",
    "            test_f1_zero = test_metrics[\"0\"][\"f1-score\"]\n",
    "            test_f1_one = test_metrics[\"1\"][\"f1-score\"]\n",
    "\n",
    "            results = {\"model\": model}\n",
    "            results.update(vect_choice)\n",
    "            results.update(model_param)\n",
    "            results.update({\"val_f1_weighted\": val_f1_weighted,  \n",
    "                            \"val_f1_zero\": val_f1_zero,\n",
    "                            \"val_f1_one\": val_f1_one,\n",
    "                            \"val_accuracy\": val_accuracy})\n",
    "            results.update({\"test_f1_weighted\": test_f1_weighted, \n",
    "                            \"test_f1_zero\": test_f1_zero,\n",
    "                            \"test_f1_one\": test_f1_one,\n",
    "                            \"test_accuracy\": test_accuracy})\n",
    "            gridsearch_results.append(results)\n",
    "            ind += 1\n",
    "    final_results = pd.DataFrame.from_records(gridsearch_results)\n",
    "    final_results = final_results.sort_values(by=[\"val_f1_one\", \"test_f1_one\"], ascending=False)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlvc_lae23Vw"
   },
   "source": [
    "# Log Reg\n",
    "\n",
    "SMOTE performs better than ROS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cupog-ckyYG6"
   },
   "outputs": [],
   "source": [
    "bert_embeddings_ros = vectorize_dataset_ros()\n",
    "bert_embeddings_smote = vectorize_dataset_smote()\n",
    "\n",
    "final_lr_results_ros = hyperparam_search(bert_embeddings_ros,\"log_reg\", LogisticRegression, logreg_paramgrid)\n",
    "final_lr_results_smote = hyperparam_search(bert_embeddings_smote,\"log_reg\", LogisticRegression, logreg_paramgrid)\n",
    "\n",
    "#final_lr_results.to_csv(\"model_results/bowtfidf/logreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LD4OkPq16Ar5",
    "outputId": "400623ad-9819-4f22-a112-f130987ea955"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lr_results_ros.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsqdkX1xQBkU",
    "outputId": "a17f7a12-6144-421b-cd28-569d9482d1ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_lr_results_smote.model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "811Bf0Mu2UNn"
   },
   "outputs": [],
   "source": [
    "#best params\n",
    "lr_params = {\n",
    "    \"C\": [0.1],\n",
    "    'class_weight': ['balanced'],\n",
    "    'penalty':['l2'],\n",
    "    'solver':['lbfgs']\n",
    "}\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient(check_length=False)\n",
    "lr_paramgrid = list(ParameterGrid(lr_params))\n",
    "\n",
    "bert_train = bc.encode(list(data.sentence))\n",
    "#oversample\n",
    "bert_train_smote,bert_train_smote_y = oversample_smote(bert_train,data.relevance)\n",
    "\n",
    "final_model = LogisticRegression(**lr_paramgrid[0])\n",
    "final_model.fit(bert_train_smote, bert_train_smote_y)\n",
    "DATA_FOLDER = \"../data/\"\n",
    "\n",
    "model_pkl_filename = DATA_FOLDER + \"saved_models/relevance_models/model_LR_BERT.pkl\"\n",
    "with open(model_pkl_filename, 'wb') as file:\n",
    "    pickle.dump(final_model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKyGMlrM1Ndd"
   },
   "source": [
    "# SVM\n",
    "\n",
    "SMOTE performs better than ROS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeQpV304vPOC"
   },
   "outputs": [],
   "source": [
    "final_svm_results_smote = hyperparam_search(bert_embeddings_smote,\"svm\", SVC, svm_paramgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktdlsBX6QX_1",
    "outputId": "013bb261-2a4e-430a-aa28-8ac1c6308745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_svm_results_smote.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oM0DKGdkIK1v"
   },
   "outputs": [],
   "source": [
    "final_svm_results_smote[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVJHpWnKRS-c"
   },
   "outputs": [],
   "source": [
    "final_svm_results_ros = hyperparam_search(bert_embeddings_ros,\"svm\", SVC, svm_paramgrid)\n",
    "\n",
    "final_svm_results_ros.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZPytyhLIH2G"
   },
   "outputs": [],
   "source": [
    "final_svm_results_ros[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ey3xoW_Uvfnm"
   },
   "outputs": [],
   "source": [
    "# Instantiate model grid that gives highest validtion weighted F1 (Class 1)\n",
    "svm_params = {\n",
    "    \"C\": [0.1],\n",
    "    \"kernel\": [\"poly\"],\n",
    "    \"gamma\": [\"scale\"],\n",
    "    \"class_weight\": ['balanced'],\n",
    "    \"probability\": [True]\n",
    "}\n",
    "\n",
    "\n",
    "from bert_serving.client import BertClient\n",
    "bc = BertClient(check_length=False)\n",
    "\n",
    "bert_train = bc.encode(list(data.sentence))\n",
    "#oversample\n",
    "bert_train_smote,bert_train_smote_y = oversample_smote(bert_train,data.relevance)\n",
    "svm_paramgrid = list(ParameterGrid(svm_params))\n",
    "\n",
    "final_model = SVC(**svm_paramgrid[0])\n",
    "final_model.fit(bert_train_smote, bert_train_smote_y)\n",
    "DATA_FOLDER = \"../data/\"\n",
    "\n",
    "model_pkl_filename = DATA_FOLDER + \"saved_models/relevance_models/model_SVM_BERT.pkl\"\n",
    "with open(model_pkl_filename, 'wb') as file:\n",
    "    pickle.dump(final_model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wC-2mzLRHHo"
   },
   "source": [
    "## Generate Fold Predictions for Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0IhABV5IREs0"
   },
   "outputs": [],
   "source": [
    "def custom_k_fold(model_grid, column, data, model_name, model_fn):\n",
    "    \n",
    "    # Generate fold predictions\n",
    "    fold_num = 1\n",
    "    for tf_combi in data:\n",
    "        train = tf_combi[0]\n",
    "        predict_on = tf_combi[1]\n",
    "        predict_label = predict_on.relevance\n",
    "        \n",
    "        # Vectorise Data\n",
    "        # for v in vectorizer_grid:\n",
    "        #     vectorizer = vectFunc(**v)\n",
    "        # vec_train = vectorizer.fit_transform(train[column])\n",
    "        # vec_predict_on = vectorizer.transform(predict_on[column])\n",
    "        \n",
    "        # Vectorise Data\n",
    "        from bert_serving.client import BertClient\n",
    "        bc = BertClient(check_length=False)\n",
    "\n",
    "        vec_train = bc.encode(list(train[column]))\n",
    "        vec_predict_on = bc.encode(list(predict_on[column]))\n",
    "\n",
    "\n",
    "        # Get Labels\n",
    "        train_label = train.relevance\n",
    "        \n",
    "        # Oversample\n",
    "        vec_train_over, train_label_over = oversample_smote(vec_train, train_label)\n",
    "        \n",
    "        # Fit Model\n",
    "        for m in model_grid:\n",
    "            model = model_fn(**m)\n",
    "        model.fit(vec_train_over, train_label_over)\n",
    "        predictions = model.predict_proba(vec_predict_on)\n",
    "        \n",
    "        # Create Dataframe and output\n",
    "        df = pd.DataFrame(data=predictions, columns = [model_name+'_prob_0', model_name+'_prob_1'])\n",
    "\n",
    "        \n",
    "        if fold_num <=5:\n",
    "            path = DATA_FOLDER + \"fold_predictions/\" + model_name + \"/\" + model_name + '_fold' + str(fold_num) +'.csv'\n",
    "        else:\n",
    "            path = DATA_FOLDER + \"fold_predictions/\" + model_name + \"/\" + model_name + '_test.csv'\n",
    "        \n",
    "        df.to_csv(path, index=False)\n",
    "        \n",
    "        fold_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Vi4zpTRRFCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=4013, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IGUcDbBDRFV3"
   },
   "outputs": [],
   "source": [
    "ind=1\n",
    "for train_index, test_index in kf.split(trainval.reset_index()):\n",
    "    tr = trainval.reset_index().iloc[train_index]\n",
    "    val = trainval.reset_index().iloc[test_index]\n",
    "    tr.to_csv('folds/train_folds_{ind}.csv'.format(ind=ind), index=False)\n",
    "    val.to_csv('folds/val_folds_{ind}.csv'.format(ind=ind), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "5wKkEcKlRO97"
   },
   "outputs": [],
   "source": [
    "# Import Data\n",
    "DATA_FOLDER = \"../data/\"\n",
    "train1 = pd.read_csv(DATA_FOLDER + 'folds/train_folds_1.csv')\n",
    "train2 = pd.read_csv(DATA_FOLDER + 'folds/train_folds_2.csv')\n",
    "train3 = pd.read_csv(DATA_FOLDER + 'folds/train_folds_3.csv')\n",
    "train4 = pd.read_csv(DATA_FOLDER + 'folds/train_folds_4.csv')\n",
    "train5 = pd.read_csv(DATA_FOLDER + 'folds/train_folds_5.csv')\n",
    "\n",
    "fold1 = pd.read_csv(DATA_FOLDER + 'folds/val_folds_1.csv')\n",
    "fold2 = pd.read_csv(DATA_FOLDER + 'folds/val_folds_2.csv')\n",
    "fold3 = pd.read_csv(DATA_FOLDER + 'folds/val_folds_3.csv')\n",
    "fold4 = pd.read_csv(DATA_FOLDER + 'folds/val_folds_4.csv')\n",
    "fold5 = pd.read_csv(DATA_FOLDER + 'folds/val_folds_5.csv')\n",
    "\n",
    "train_all = pd.read_csv(DATA_FOLDER + 'folds/trainval.csv')\n",
    "testset = pd.read_csv(DATA_FOLDER + 'folds/test.csv')\n",
    "\n",
    "# store in suitable data structure\n",
    "data = [(train1, fold1), (train2, fold2),(train3, fold3), (train4, fold4), (train5, fold5), (train_all, testset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj0cIezdW1LW"
   },
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BeEIawQ9WTNX"
   },
   "outputs": [],
   "source": [
    "# Instantiate model grid that gives highest validtion weighted F1 (Class 1)\n",
    "lr_params = {\n",
    "    \"C\": [0.1],\n",
    "    'class_weight': ['balanced'],\n",
    "    'penalty':['l2'],\n",
    "    'solver':['lbfgs']\n",
    "}\n",
    "\n",
    "lr_paramgrid = list(ParameterGrid(lr_params))\n",
    "\n",
    "# Best text processing\n",
    "column = 'sentence'\n",
    "\n",
    "# Model Function\n",
    "model_fn = LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QwJqIFklWXXJ"
   },
   "outputs": [],
   "source": [
    "custom_k_fold(lr_paramgrid, column, data, \"LR_BERT\", model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0GdjgTrWoqW"
   },
   "source": [
    "## SVM\n",
    "\n",
    "Not used for stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjMQL2z4WpNq"
   },
   "outputs": [],
   "source": [
    "# Instantiate model grid that gives highest validtion weighted F1 (Class 1)\n",
    "svm_params = {\n",
    "    \"C\": [0.1],\n",
    "    \"kernel\": [\"poly\"],\n",
    "    \"gamma\": [\"scale\"],\n",
    "    \"class_weight\": ['balanced'],\n",
    "    \"probability\": [True] # must be true\n",
    "}\n",
    "\n",
    "svm_paramgrid = list(ParameterGrid(svm_params))\n",
    "\n",
    "\n",
    "#Best text processing\n",
    "column = 'sentence'\n",
    "\n",
    "# Model Function\n",
    "model_fn = SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T07nZxgGWtoi"
   },
   "outputs": [],
   "source": [
    "custom_k_fold(svm_paramgrid, column, data, \"SVM_BERT\", model_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auR-Jhnkr5XP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hkj3wB7flLt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "relevance-model-bertembeddings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
