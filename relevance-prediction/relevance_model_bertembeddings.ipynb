{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4AbYWwPirPV"
   },
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Xbp-Xa1hcbq",
    "outputId": "c1f21fcd-d5e1-443d-9244-796b5f9edc07"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7VqWBsChVNa"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../Data/labelled_data/all_labelled_17Oct.csv\" \n",
    "data = pd.read_csv(DATA_PATH)\n",
    "#data= pd.read_csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSmEIfzUZLe4-7MyoUVW-NP0kndzRgsBQWe3WwBOxmU5wIQ75oRg1li3TImN1RFSSdxIO5K8T4h2n4E/pub?gid=0&single=true&output=csv\")\n",
    "data.columns = ['index', 'sentence', 'relevance', 'carbon_class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5z03Uf_H-HTI",
    "outputId": "e4601e93-05a6-4925-e625-d31d2c497c72"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mo6X1pYw-LRi",
    "outputId": "91c5089e-a2e6-42e9-e0c0-5f686a0a7f7d"
   },
   "outputs": [],
   "source": [
    "data.relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kss8IWZh-Qx5",
    "outputId": "f855739e-eac0-4f99-a277-66ab1c8b9a8f"
   },
   "outputs": [],
   "source": [
    "data.carbon_class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5NwaJjtxm3G"
   },
   "source": [
    "### Preprocess text before emedding it\n",
    "1. dont remove numbers because we want to capture numbers\n",
    "2. dont lemmatize etc because BERT dont need\n",
    "1. ONLY remove all punctuations except except %,$,&\n",
    "- upper/lower casing dont affect embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fIenLl1bfjCd"
   },
   "outputs": [],
   "source": [
    "def remove_numbers(string):\n",
    "    return ''.join(i for i in string if not i.isdigit())\n",
    "\n",
    "def remove_punc(s):\n",
    "    import string\n",
    "    exclude = string.punctuation\n",
    "    final_punc = ''.join(list(i for i in exclude if i not in ['%', '$', '&']))\n",
    "    s = ''.join(ch for ch in s if ch not in list(final_punc))\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPFcItwjxggZ"
   },
   "outputs": [],
   "source": [
    "data.sentence = data.sentence.map(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ew1hCZ-lfYA"
   },
   "outputs": [],
   "source": [
    "train, val, test = \\\n",
    "              np.split(data.sample(frac=1, random_state=4103), \n",
    "                       [int(.6*len(data)), int(.8*len(data))])\n",
    "trainval =pd.concat([train, val])\n",
    "labels = [train.relevance, val.relevance, test.relevance, trainval.relevance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMILMqNvrb04"
   },
   "source": [
    "### BERT embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vt-cwriBrKcU",
    "outputId": "aa354118-a2ff-4eb2-d6bb-94753a431837"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "!pip install bert-serving-client\n",
    "!pip install -U bert-serving-server[http]\n",
    "\n",
    "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
    "!unzip uncased_L-12_H-768_A-12.zip\n",
    "!nohup bert-serving-start -model_dir=./uncased_L-12_H-768_A-12 > out.file 2>&1 &\n",
    "\n",
    "\n",
    "!ls  # you should see uncased_something_.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66N4AACr1uGs"
   },
   "outputs": [],
   "source": [
    "vect_methods = {'type': ['bert_as_a_service']}\n",
    "vect_methods_paramgrid = list(ParameterGrid(vect_methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vKIozCseFNW"
   },
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "logreg_params = { \"C\": [0.1, 0.5, 1.0, 1.5, 5], \n",
    "                 \"solver\": [\"lbfgs\", \"newton-cg\"], \n",
    "                 \"penalty\": [\"l2\", \"none\"],\n",
    "                 \"class_weight\": [\"balanced\", None]}\n",
    "logreg_paramgrid = list(ParameterGrid(logreg_params))\n",
    "\n",
    "# naive bayes\n",
    "nb_params = {\"alpha\": [0, 0.001, 0.01, 0.1, 0.25, 0.5, 1]}\n",
    "nb_paramgrid = list(ParameterGrid(nb_params))\n",
    "\n",
    "# svm\n",
    "svm_params = { \"C\": [0.1, 0.5, 1.0, 1.5, 5],\n",
    "    \"kernel\": [\"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"class_weight\": [\"balanced\", None] \n",
    "}\n",
    "\n",
    "svm_paramgrid = list(ParameterGrid(svm_params))\n",
    "\n",
    "# rf\n",
    "rf_params = [\n",
    "    {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"class_weight\": [\"balanced\", \"balanced_subsample\", None],\n",
    "        \"max_features\": [\"auto\",\"sqrt\"],\n",
    "        \"min_samples_leaf\": [1, 2, 4]\n",
    "    }\n",
    "]\n",
    "\n",
    "rf_paramgrid = list(ParameterGrid(rf_params))\n",
    "\n",
    "# dummy classifier\n",
    "dummy_params = { \"strategy\": [\"prior\"] }\n",
    "dummy_paramgrid = list(ParameterGrid(dummy_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRVrf6V1zAoI"
   },
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXeNZzh6tl_l"
   },
   "outputs": [],
   "source": [
    "#Oversampling the data\n",
    "def oversample(X,y):\n",
    "    ros = RandomOverSampler(random_state = 4103,sampling_strategy=1.0)\n",
    "    X, y = ros.fit_resample(X, y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEB-0Vc2qgzo"
   },
   "outputs": [],
   "source": [
    "def vectorize_dataset():\n",
    "    # BERT as a Service\n",
    "    from bert_serving.client import BertClient\n",
    "    bc = BertClient(check_length=False)\n",
    "\n",
    "    bert_train = bc.encode(list(train.sentence))\n",
    "    bert_val = bc.encode(list(val.sentence))\n",
    "    bert_test = bc.encode(list(test.sentence))\n",
    "    bert_trainval = bc.encode(list(trainval.sentence))\n",
    "    \n",
    "    # oversample minority class\n",
    "    bert_train_oversampled = oversample(bert_train, labels[0])\n",
    "    bert_trainval_oversampled = oversample(bert_trainval, labels[3])\n",
    "    \n",
    "    return {'bert_as_a_service': [bert_train_oversampled, bert_val, bert_test, bert_trainval_oversampled]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0AkjdoAq0gx"
   },
   "outputs": [],
   "source": [
    "def hyperparam_search(dataset,model, model_function, model_grid):\n",
    "    ind = 0 \n",
    "    gridsearch_results = []\n",
    "    dataset = dataset\n",
    "    for vect_choice in vect_methods_paramgrid:\n",
    "        vect = vect_choice['type']\n",
    "        train_hp = dataset[vect][0][0]\n",
    "        val_hp = dataset[vect][1]\n",
    "        test_hp = dataset[vect][2]\n",
    "        trainval_hp = dataset[vect][3][0]\n",
    "\n",
    "        train_label = dataset[vect][0][1]\n",
    "        val_label = labels[1]\n",
    "        test_label = labels[2]\n",
    "        trainval_label = dataset[vect][3][1]\n",
    "\n",
    "        for model_param in model_grid:\n",
    "            # fit model on train set\n",
    "            model = model_function(**model_param)\n",
    "            model.fit(train_hp, train_label)\n",
    "            val_pred = model.predict(val_hp)\n",
    "\n",
    "            # scoring\n",
    "            val_metrics = classification_report(val_label, val_pred, output_dict=True)\n",
    "            val_accuracy = val_metrics[\"accuracy\"]\n",
    "            val_f1_weighted = val_metrics[\"weighted avg\"][\"f1-score\"]\n",
    "            val_f1_zero = val_metrics[\"0\"][\"f1-score\"]\n",
    "            val_f1_one = val_metrics[\"1\"][\"f1-score\"]\n",
    "\n",
    "            # fit model on trainval set\n",
    "            model = model_function(**model_param)\n",
    "            model.fit(trainval_hp, trainval_label)\n",
    "            test_pred = model.predict(test_hp)\n",
    "\n",
    "            # scoring\n",
    "            test_metrics = classification_report(test_label, test_pred, output_dict=True)\n",
    "            test_accuracy = test_metrics[\"accuracy\"]\n",
    "            test_f1_weighted = test_metrics[\"weighted avg\"][\"f1-score\"]\n",
    "            test_f1_zero = test_metrics[\"0\"][\"f1-score\"]\n",
    "            test_f1_one = test_metrics[\"1\"][\"f1-score\"]\n",
    "\n",
    "            results = {\"model\": model}\n",
    "            results.update(vect_choice)\n",
    "            results.update(model_param)\n",
    "            results.update({\"val_f1_weighted\": val_f1_weighted,  \n",
    "                            \"val_f1_zero\": val_f1_zero,\n",
    "                            \"val_f1_one\": val_f1_one,\n",
    "                            \"val_accuracy\": val_accuracy})\n",
    "            results.update({\"test_f1_weighted\": test_f1_weighted, \n",
    "                            \"test_f1_zero\": test_f1_zero,\n",
    "                            \"test_f1_one\": test_f1_one,\n",
    "                            \"test_accuracy\": test_accuracy})\n",
    "            gridsearch_results.append(results)\n",
    "            ind += 1\n",
    "    final_results = pd.DataFrame.from_records(gridsearch_results)\n",
    "    final_results = final_results.sort_values(by=[\"val_f1_one\", \"test_f1_one\"], ascending=False)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlvc_lae23Vw"
   },
   "source": [
    "# Log Reg\n",
    "# BERT AS A SERVICE TAKES TIME TO ENCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cupog-ckyYG6"
   },
   "outputs": [],
   "source": [
    "bert_embeddings = vectorize_dataset()\n",
    "final_lr_results = hyperparam_search(bert_embeddings,\"log_reg\", LogisticRegression, logreg_paramgrid)\n",
    "#final_lr_results.to_csv(\"model_results/bowtfidf/logreg.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LD4OkPq16Ar5",
    "outputId": "12510c30-3b66-4621-d09c-3e6572325aea"
   },
   "outputs": [],
   "source": [
    "final_lr_results.model[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7aJL4r6308g"
   },
   "source": [
    "# Naive Bayes \n",
    "- word embeddings have negative values which cannot be utilised for Naive Bayes\n",
    "\n",
    "Negative values in data passed to MultinomialNB (input X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jVgJN5oit6-M"
   },
   "outputs": [],
   "source": [
    "final_nb_results = hyperparam_search(\"nb\", MultinomialNB, nb_paramgrid)\n",
    "#final_nb_results.to_csv(\"model_results/bowtfidf/nb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WKyGMlrM1Ndd"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeQpV304vPOC"
   },
   "outputs": [],
   "source": [
    "final_svm_results = hyperparam_search(bert_embeddings,\"svm\", SVC, svm_paramgrid)\n",
    "#final_svm_results.to_csv(\"model_results/bowtfidf/svm.csv\", index=False)\n",
    "final_svm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XVJHpWnKRS-c",
    "outputId": "69e9783f-2256-45ed-d562-eee8c4f27de7"
   },
   "outputs": [],
   "source": [
    "final_svm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4xCGoAH2Drt"
   },
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "ZhWPls7Xv8xU",
    "outputId": "fe73284b-9fb7-43c8-9079-e292ef828f42"
   },
   "outputs": [],
   "source": [
    "final_rf_results = hyperparam_search(bert_embeddings,\"rf\", RandomForestClassifier, rf_paramgrid)\n",
    "#final_rf_results.to_csv(\"model_results/bowtfidf/rf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hI7O1epfxnYh"
   },
   "source": [
    "# Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DH_JOt38xtAr"
   },
   "outputs": [],
   "source": [
    "final_dummy_results = hyperparam_search(bert_embeddings,\"dummy\", DummyClassifier, dummy_paramgrid)\n",
    "#final_dummy_results.to_csv(\"model_results/bowtfidf/dummy.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmI8quui7bAh"
   },
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpDD5vMi2Rl7"
   },
   "outputs": [],
   "source": [
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression(C=0.1, class_weight='balanced', dual=False,\n",
    "                                         fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                                         max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                                         random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                                         warm_start=False)))\n",
    "\tlevel0.append(('svm', SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0, \n",
    "                           decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
    "                           max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "                           tol=0.001, verbose=False)))\n",
    "\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LogisticRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    "\n",
    "\n",
    "# get a list of best models to evaluate on \n",
    "def get_models():\n",
    "    models = dict()\t\n",
    "    models['lr'] = LogisticRegression(C=0.1, class_weight='balanced', dual=False, fit_intercept=True, intercept_scaling=1, l1_ratio=None, max_iter=100, multi_class='auto', n_jobs=None, penalty='l2', random_state=None, solver='lbfgs', tol=0.0001, verbose=0,warm_start=False)\t\n",
    "    models['svm'] = SVC(C=0.1, break_ties=False, cache_size=200, class_weight='balanced', coef0=0.0,decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
    "                        max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)\n",
    "    models['stacking'] = get_stacking()\n",
    "    return models\n",
    "\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring=make_scorer(f1_score, pos_label=1), cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M6KurpuE7_Z_",
    "outputId": "57651097-9fd1-4f54-b421-7bb1ab6f114a"
   },
   "outputs": [],
   "source": [
    "from numpy import mean,std\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# get the models to evaluate\n",
    "X, y = bert_embeddings[\"bert_as_a_service\"][3][0] , bert_embeddings[\"bert_as_a_service\"][3][1]\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hw2uiiyKlmdz"
   },
   "source": [
    "### carbon classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oLDT-TWJWKME",
    "outputId": "66d4cedf-23f7-43cc-9ce0-66693682abab"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', stop_words = 'english')\n",
    "for i in range(5):\n",
    "    print(f\"Class {i}\")\n",
    "    X_train = data.loc[data.carbon_class == float(i)].sentence\n",
    "    # fit_transform on training val data\n",
    "    X_traintfidf = tfidf.fit_transform(X_train)\n",
    "    terms = tfidf.get_feature_names()\n",
    "\n",
    "    # sum tfidf frequency of each term through documents\n",
    "    sums = X_traintfidf.sum(axis=0)\n",
    "\n",
    "    # connecting term to its sums frequency\n",
    "    df = []\n",
    "    for col, term in enumerate(terms):\n",
    "        df.append( (term, sums[0,col] ))\n",
    "\n",
    "    ranking = pd.DataFrame(df, columns=['term','rank'])\n",
    "    print(ranking.sort_values('rank', ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cEavPlm9mkAs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "relevance-model-bertembeddings",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
