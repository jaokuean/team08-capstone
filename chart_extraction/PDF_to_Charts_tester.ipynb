{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart Extraction \n",
    "## 1. Install all the prerequisite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2image\n",
    "!pip install pytesseract\n",
    "!pip install opencv-python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use for checking files in dir\n",
    "import os\n",
    "\n",
    "# Extract each pdf page to image\n",
    "from pdf2image import convert_from_path \n",
    "from pdf2image.exceptions import (\n",
    " PDFInfoNotInstalledError,\n",
    " PDFPageCountError,\n",
    " PDFSyntaxError\n",
    ")\n",
    "\n",
    "# Image Processing\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gather Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChartExtraction_Output/Citibank_nan/pages\n",
      "ChartExtraction_Output/Citibank_nan/test\n"
     ]
    }
   ],
   "source": [
    "# MAIN INPUT \n",
    "# Input codes (only in .pdf files)\n",
    "path1 = 'reports/DBS Sustainability Report 2020.pdf'\n",
    "path2 = 'reports/Daikin_SR_report.pdf'\n",
    "path3 = 'reports/pingan SR report.pdf'\n",
    "path4 = 'ChartExtraction_Output/Citibank_nan'\n",
    "path5 = 'ChartExtraction_Output/ICBC_2020'\n",
    "path6 = 'ChartExtraction_Output/BDO Unibank_2020'\n",
    "\n",
    "# Change report\n",
    "path = path4 \n",
    "source_path = path + '/pages'\n",
    "output_path = path + '/test'\n",
    "print(source_path)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Program Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal parameters for graph detection\n",
    "set_column_gap = 15\n",
    "set_height_limit = 0\n",
    "set_width_limit = 0\n",
    "set_area_limit = 80000\n",
    "\n",
    "set_scale_factor = 2.5 # Extend horizontal and vertical axis of bounding boxes\n",
    "scale_horizontal = set_scale_factor*64\n",
    "scale_vertical = set_scale_factor*64\n",
    "\n",
    "def zero_runs(a):\n",
    "    # Create an array that is 1 where a is 0, and pad each end with an extra 0.\n",
    "    iszero = np.concatenate(([0], np.equal(a, 0).view(np.int8), [0]))\n",
    "    absdiff = np.abs(np.diff(iszero))\n",
    "    # Runs start and end where absdiff is 1.\n",
    "    ranges = np.where(absdiff == 1)[0].reshape(-1, 2)\n",
    "    return ranges\n",
    "\n",
    "# Method to check if extracted article is valid\n",
    "def checkDim(height, width, area):\n",
    "    #print(f\"{height} x {width} = {area}\")\n",
    "    if(height <= set_height_limit):\n",
    "        return False\n",
    "    if(width <= set_width_limit):\n",
    "        return False\n",
    "    if(area <= set_area_limit):\n",
    "        return False\n",
    "    return True\n",
    "def process_image(image, pageNum, task):\n",
    "    original = image.copy()\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (20,10))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        area = cv2.contourArea(c)\n",
    "        if w/h > 2 and area > 1000:\n",
    "            cv2.drawContours(dilate, [c], -1, (0,0,0), -1)   \n",
    "            \n",
    "    boxes = []\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        boxes.append([x,y, x+w,y+h])\n",
    "    \n",
    "    boxes = np.asarray(boxes)\n",
    "    try:\n",
    "        x = np.min(boxes[:,0])\n",
    "        y = np.min(boxes[:,1])\n",
    "        w = np.max(boxes[:,2]) - x\n",
    "        h = np.max(boxes[:,3]) - y\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    cv2.rectangle(image, (x,y), (x + w,y + h), (36,255,12), 3)\n",
    "    ROI = original[y:y+h, x:x+w]\n",
    "\n",
    "    cv2.imwrite(path + \"/test/GDFI_\"+str(pageNum)+str(task)+\"_img.png\", image)\n",
    "    cv2.imwrite(path +\"/test/GDFI_\"+str(pageNum)+str(task)+\"_thresh.png\", thresh)\n",
    "    cv2.imwrite(path +\"/test/GDFI_\"+str(pageNum)+str(task)+\"_dilate.png\", dilate)\n",
    "    cv2.imwrite(path +\"/test/GDFI_\"+str(pageNum)+str(task)+\"_ROI.png\", ROI)\n",
    "    \n",
    "def process_image2(img):\n",
    "    original = image.copy()\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # turn img to grey\n",
    "    img_gray_inverted = 255 - img_gray # Invert back to normal\n",
    "\n",
    "    row_means = cv2.reduce(img_gray_inverted, 1, cv2.REDUCE_AVG, dtype=cv2.CV_32F).flatten()\n",
    "    row_gaps = zero_runs(row_means)\n",
    "    row_cutpoints = (row_gaps[:,0] + row_gaps[:,1] - 1) / 2\n",
    "    \n",
    "    bounding_boxes = []\n",
    "    for n,(start,end) in enumerate(zip(row_cutpoints, row_cutpoints[1:])):\n",
    "        line = img[int(start):int(end)]\n",
    "        line_gray_inverted = img_gray_inverted[int(start):int(end)]\n",
    "\n",
    "        column_means = cv2.reduce(line_gray_inverted, 0, cv2.REDUCE_AVG, dtype=cv2.CV_32F).flatten()\n",
    "        column_gaps = zero_runs(column_means)\n",
    "        column_gap_sizes = column_gaps[:,1] - column_gaps[:,0]\n",
    "        column_cutpoints = (column_gaps[:,0] + column_gaps[:,1] - 1) / 2\n",
    "\n",
    "        filtered_cutpoints = column_cutpoints[column_gap_sizes > set_column_gap] # this part can use ML too \n",
    "\n",
    "        for xstart,xend in zip(filtered_cutpoints, filtered_cutpoints[1:]):\n",
    "            bounding_boxes.append(((int(xstart), int(start)), (int(xend), int(end))))\n",
    "\n",
    "    count = 0\n",
    "    result = img.copy()\n",
    "\n",
    "    for bounding_box in bounding_boxes:\n",
    "        \n",
    "        height = bounding_box[1][1]-bounding_box[0][1]\n",
    "        width = bounding_box[1][0]-bounding_box[0][0]\n",
    "        area = height * width\n",
    "       \n",
    "        # represents the top left corner of rectangle\n",
    "        # (x_top, y_top) \n",
    "        # x_top = bounding_box[0][0]\n",
    "        # y_top = bounding_box[0][1]\n",
    "        \n",
    "        # represents the bottom right corner of rectangle\n",
    "        # (x_bot, y_tbot) \n",
    "        # x_bot = bounding_box[1][0]\n",
    "        # y_bot = bounding_box[1][1]\n",
    "        \n",
    "        # height = y_bot - y_top\n",
    "        # height =  bounding_box[1][1] - bounding_box[0][1]\n",
    "        \n",
    "        # width = x_bot - x_top\n",
    "        # width = bounding_box[1][0] - bounding_box[0][0]\n",
    "        \n",
    "        if(checkDim(height, width, area) == True):\n",
    "            count = count + 1\n",
    "            # Extend bounding lines\n",
    "            new_x_top = bounding_box[0][0]-int(scale_horizontal)\n",
    "            new_y_top = bounding_box[0][1]-int(scale_vertical)\n",
    "            new_x_bot = bounding_box[1][0]+int(scale_horizontal)\n",
    "            new_y_bot = bounding_box[1][1]+int(scale_vertical)\n",
    "            \n",
    "            # To prevent error on -ve values\n",
    "            if(new_x_top < 0):\n",
    "                new_x_top = 0\n",
    "            if(new_y_top < 0):\n",
    "                new_y_top = 0\n",
    "            if(new_x_bot < 0):\n",
    "                new_x_bot = 0\n",
    "            if(new_y_bot < 0):\n",
    "                new_y_bot = 0\n",
    "                \n",
    "            # Re-calculate bounding lines\n",
    "            new_width = new_x_bot - new_x_top\n",
    "            new_height = new_y_bot - new_y_top\n",
    "            \n",
    "            # if condition pass, crop image and output\n",
    "            X, Y, W, H = new_x_top, new_y_top, new_width, new_height\n",
    "            cropped_image = result[Y:Y+H, X:X+W]\n",
    "            \n",
    "            output_test_img = path + \"/articles/page\" + str(pageNum) + \"_\"+ str(task) +\"_\" + str(count) +\".png\"\n",
    "            cv2.imwrite(output_test_img, cropped_image)\n",
    "            cv2.rectangle(result, (new_x_top,new_y_top), (new_x_bot,new_y_bot), (0, 0, 255), 2)\n",
    "    cv2.imwrite(output_path+\"/page\"+str(pageNum) + \"_part\"+str(task)+\".png\" , result)\n",
    "            \n",
    "# Main image processing method to draw bounding lines of graphs/charts\n",
    "def isLandscape(h,w):\n",
    "    if(w>h):\n",
    "        print(\"landscape\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"portrait\")\n",
    "        return False\n",
    "    \n",
    "def page_to_articles(pageNum, fileHeader):\n",
    "    print(f\"=>starting on page {pageNum} : {fileHeader}\")\n",
    "    img_list = []\n",
    "    img = cv2.imread(fileHeader, cv2.IMREAD_COLOR) # Identify img\n",
    "    h,w,c = img.shape\n",
    "    print (h, w, c)\n",
    "    if(isLandscape(h,w)):\n",
    "        width_cutoff = w // 2\n",
    "        s1 = img[:, :width_cutoff]\n",
    "        s2 = img[:, width_cutoff:]        \n",
    "        process_image(s1, pageNum, \"a\")\n",
    "        process_image(s2, pageNum, \"b\")\n",
    "    else:\n",
    "        process_image(img, pageNum,\"0\")\n",
    "\n",
    "\n",
    "# TODO: filter page with relevant ESG keywords\n",
    "def filter_pages(pageNum):\n",
    "    if(pageNum%2==0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : ChartExtraction_Output/Citibank_nan/pages/9.png\n",
      "portrait\n",
      "=>starting on page 1 : ChartExtraction_Output/Citibank_nan/pages/9.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "2 : ChartExtraction_Output/Citibank_nan/pages/17.png\n",
      "portrait\n",
      "=>starting on page 2 : ChartExtraction_Output/Citibank_nan/pages/17.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "3 : ChartExtraction_Output/Citibank_nan/pages/16.png\n",
      "portrait\n",
      "=>starting on page 3 : ChartExtraction_Output/Citibank_nan/pages/16.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "4 : ChartExtraction_Output/Citibank_nan/pages/10.png\n",
      "portrait\n",
      "=>starting on page 4 : ChartExtraction_Output/Citibank_nan/pages/10.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "5 : ChartExtraction_Output/Citibank_nan/pages/21.png\n",
      "portrait\n",
      "=>starting on page 5 : ChartExtraction_Output/Citibank_nan/pages/21.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "6 : ChartExtraction_Output/Citibank_nan/pages/20.png\n",
      "portrait\n",
      "=>starting on page 6 : ChartExtraction_Output/Citibank_nan/pages/20.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "7 : ChartExtraction_Output/Citibank_nan/pages/22.png\n",
      "portrait\n",
      "=>starting on page 7 : ChartExtraction_Output/Citibank_nan/pages/22.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "8 : ChartExtraction_Output/Citibank_nan/pages/23.png\n",
      "portrait\n",
      "=>starting on page 8 : ChartExtraction_Output/Citibank_nan/pages/23.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "9 : ChartExtraction_Output/Citibank_nan/pages/24.png\n",
      "portrait\n",
      "=>starting on page 9 : ChartExtraction_Output/Citibank_nan/pages/24.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "10 : ChartExtraction_Output/Citibank_nan/pages/19.png\n",
      "portrait\n",
      "=>starting on page 10 : ChartExtraction_Output/Citibank_nan/pages/19.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "11 : ChartExtraction_Output/Citibank_nan/pages/5.png\n",
      "portrait\n",
      "=>starting on page 11 : ChartExtraction_Output/Citibank_nan/pages/5.png\n",
      "2339 1654 3\n",
      "portrait\n",
      "JOB COMPLETE+++++++++\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for filename in os.listdir(source_path):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        counter = counter + 1\n",
    "        print(f\"{counter} : {os.path.join(source_path, filename)}\")\n",
    "        imagepath = os.path.join(source_path, filename)\n",
    "        \n",
    "        # Read first image to check orientation\n",
    "        img = cv2.imread(imagepath, cv2.IMREAD_COLOR)\n",
    "        h,w,c = img.shape\n",
    "        #print (h, w, c)\n",
    "        \n",
    "        # Check orientation\n",
    "        if(w>h):\n",
    "            print(\"landscape\")\n",
    "            # Split image into 2 \n",
    "            width_cutoff = w // 2\n",
    "            s1 = img[:, :width_cutoff]\n",
    "            s2 = img[:, width_cutoff:]\n",
    "            page_to_articles(counter,imagepath)\n",
    "            counter = counter + 1\n",
    "            page_to_articles(counter,imagepath)\n",
    "        else:\n",
    "            print(\"portrait\")\n",
    "            page_to_articles(counter,imagepath)\n",
    "            # run extraction\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "print(\"JOB COMPLETE+++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Run Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "            filter_img = cv2.imread(image_path, cv2.IMREAD_COLOR)        \n",
    "    # list of keywords\n",
    "            dictionary = [\"carbon\",\"co2\",\"environment\",\"GHG emissions\",\"Greenhouse Gas\",\n",
    "                                     \"carbon footprint\",\"carbon emissions\",\"Scope 1\",\"Scope 2\",\n",
    "                                     \"Scope 3\", \"WACI\",\"Carbon Intensity\",\"carbon pricing\",\"net-zero\",\n",
    "                                     \"metrics and targets\",\"TCFD\",\"sustainability goals\",\"decarbonisation\",\n",
    "                                     \"climate\",'energy','emission', 'emissions', 'renewable', 'carbon', 'fuel', 'power', \n",
    "                                     'green', 'gas', 'green energy', 'sustainable', 'climate', 'sustainability', \n",
    "                                     'environmental', 'environment', 'GHG','decarbon', 'energy consumption', \n",
    "                                     'paper consumption','water consumption', 'carbon intensity', 'waste management', \n",
    "                                     'electricity consumption', 'cdp', 'global warming', 'business travel', \n",
    "                         ]\n",
    "\n",
    "\n",
    "            # list of units\n",
    "            units = ['tonnes', 'tons', 'kWh', ' kg ', 'kilogram', 'kilowatt hour', \n",
    "                   'gigajoules', 'GJ', 'litre', 'liter', 'CO2e', 'tCO', 't CO', 'MWh', \n",
    "                   'megawatt hour', '%', 'cubic metres', 'per employee']\n",
    "\n",
    "            # Filter images with too much text\n",
    "            text = pytesseract.image_to_string(filter_img)\n",
    "            list_of_text = text.split()\n",
    "            #print(list_of_text)\n",
    "            # Remove numbers\n",
    "            \n",
    "            n = 0\n",
    "            if any(keyword in text.lower() for keyword in dictionary) and any(unit in text for unit in units):\n",
    "                print(f\"============FOUND KEYWORD {pageNum}_{count}_{n}===================\")\n",
    "                if(10 < len(list_of_text) < 150):\n",
    "                    # Output result\n",
    "                    n = n + 1\n",
    "                    print(f\"============FOUND {pageNum}_{count}_{n}, LENGTH = {len(list_of_text)}===================\")\n",
    "                    ROI_image_path = fileHeader + \"/final_page_\" +str(pageNum)+ \"_\"+ str(count) + \"_\"+ str(n) + \"_ROI.png\"\n",
    "                    cv2.imwrite(ROI_image_path, filter_img)\n",
    "                    img_list.append(ROI_image_path)\n",
    "                else:\n",
    "                    print(f\"{image_path} = {len(list_of_text)}\")\n",
    "            else:\n",
    "                print(f\"============REJECTED {pageNum}_{count}_{n}, LENGTH = {len(list_of_text)}===================\")\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chart_extraction(url, pages, copy_to_path):\n",
    "# check if URL is pdf\n",
    "    if \".pdf\" not in url:\n",
    "        print(\"URL is not a PDF.\")\n",
    "        return \"nan\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        print(\"Requests failed.\")\n",
    "        return \"nan\"\n",
    "    \n",
    "    os.makedirs(copy_to_path)\n",
    "    os.makedirs(copy_to_path + '/pages') # Create dir for page output\n",
    "    os.makedirs(copy_to_path + '/articles') # Create dir for chart extraction output\n",
    "    os.makedirs(copy_to_path + '/test') # Create dir for test outputs\n",
    "    \n",
    "    # convert pdf URL to image\n",
    "    images = convert_from_bytes(response.content, size=1000)\n",
    "\n",
    "    i = 1\n",
    "    image_path_obj = {}\n",
    "    \n",
    "    for page in filtered_list:\n",
    "        json_imgs = []\n",
    "        print(f\"==> Now doing page {page} ...\")\n",
    "        img_list = page_to_articles(page, copy_to_path)\n",
    "        print(f\"==> Finished Page {page} ...\\n\")\n",
    "        json_imgs.append(img_list)    \n",
    "        image_path_obj[str(page)] = json_imgs\n",
    "    \n",
    "    # remove program folders\n",
    "    os.remove(copy_to_path + '/pages') # Create dir for page output\n",
    "    os.remove(copy_to_path + '/articles') # Create dir for chart extraction output\n",
    "    os.remove(copy_to_path + '/test') # Create dir for test outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "f = open('all_asian_banks_preprocessed_vfinal.json',)\n",
    " \n",
    "# returns JSON object as a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Iterating through the json list\n",
    "source = \"gdrive/MyDrive/TableExtraction_Output/\"\n",
    "\n",
    "json_lst = []\n",
    "\n",
    "for i in data[:5]:\n",
    "    company = i['company']\n",
    "    year = i['year']\n",
    "    pdf_url = i['url']\n",
    "    pages = []\n",
    "    for j in i['filtered_report_tables_direct']:\n",
    "        pages.append(j)\n",
    "    \n",
    "    json_obj = {}\n",
    "    json_obj['company'] = company\n",
    "    json_obj['year'] = year\n",
    "    json_obj['pdf_url'] = pdf_url\n",
    "\n",
    "    path = source + company + '_' + year\n",
    "    os.mkdir(path)\n",
    "    try:\n",
    "        json_obj['images_path'] = chart_extraction(pdf_url, pages, path)\n",
    "    except:\n",
    "        print(\"Error occurred in chart_extraction\")\n",
    "        json_obj['images_path'] = \"nan\"\n",
    "\n",
    "    json_lst.append(json_obj)\n",
    " \n",
    "\n",
    " \n",
    "# Closing file\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
