{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774be497",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78c851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade matplotlib\n",
    "# !pip install --upgrade seaborn\n",
    "# !pip install --ignore-installed pyyaml==5.1\n",
    "# !pip install torch==1.7\n",
    "# !pip install torchvision==0.8.1\n",
    "\n",
    "# import torch, torchvision\n",
    "# print(torch.__version__, torch.cuda.is_available())\n",
    "# !gcc --version\n",
    "\n",
    "# import getpass\n",
    "# import os\n",
    "# password = getpass.getpass()\n",
    "# command = \"sudo -S apt install tesseract-ocr \" \n",
    "# os.system('echo %s | %s' % (password, command))\n",
    "\n",
    "# !pip install pytesseract\n",
    "\n",
    "# import torch, torchvision\n",
    "# torch.__version__\n",
    "# assert torch.__version__.startswith(\"1.7\")\n",
    "\n",
    "# !pip install 'git+https://github.com/facebookresearch/detectron2.git' (previously worked)\n",
    "# !git clone https://github.com/facebookresearch/detectron2.git\n",
    "\n",
    "# !pip install opencv-python\n",
    "\n",
    "# conda install pytorch torchvision torchaudio -c pytorch\n",
    "\n",
    "# !pip install camelot-py[plot]\n",
    "# !pip install pdf2image\n",
    "\n",
    "# !pip install ghostscript\n",
    "# !pip install camelot-py[cv]\n",
    "# !pip install excalibur-py\n",
    "# !apt install ghostscript python3-tk\n",
    "# from ctypes.util import find_library\n",
    "# print(find_library(\"gs\")) #will display libgs.so.9 if installed; will print None if not\n",
    "# !excalibur initdb -> will throw ModuleNotFoundError: No module named 'camelot.ext'\n",
    "\n",
    "# conda install -c conda-forge poppler\n",
    "\n",
    "# !pip install pickle-mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd4e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d59267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/Psarpei/Multi-Type-TD-TSR.git\n",
    "# !mv Multi-Type-TD-TSR/ Multi_Type_TD_TSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96553051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing detectron2\n",
    "# https://gilberttanner.com/blog/detectron-2-object-detection-with-pytorch\n",
    "\n",
    "# Building of Facebook's detectron2\n",
    "# Source: https://github.com/facebookresearch/detectron2/issues/300\n",
    "# Mac OS does not support CUDA, we need to force detectron2 to depend on cpu \n",
    "# change the line to -> model.to(torch.device(\"cpu\")) \n",
    "# Directory: Macintosh HD > opt > anaconda3 > lib > python 3.8 > site-packages > detectron2 > modelling > meta_arch > build.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a84108",
   "metadata": {},
   "source": [
    "3 additional dependencies: model_final.pth, All_X152.yaml, Base-RCNN-FPN.yaml (put all in Desktop folder)\n",
    "- For All_X152.yaml, access the file and change _BASE_ directory based on where you store "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348ed7e6",
   "metadata": {},
   "source": [
    "### Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1403db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb2984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd6e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f5048",
   "metadata": {},
   "source": [
    "### Preparing Multi-Type-TD-TSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0726ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "import Multi_Type_TD_TSR.google_colab.deskew as deskew\n",
    "import Multi_Type_TD_TSR.google_colab.table_detection as table_detection\n",
    "import Multi_Type_TD_TSR.google_colab.table_structure_recognition_all as tsra\n",
    "import Multi_Type_TD_TSR.google_colab.table_structure_recognition_lines as tsrl\n",
    "import Multi_Type_TD_TSR.google_colab.table_structure_recognition_wol as tsrwol\n",
    "import Multi_Type_TD_TSR.google_colab.table_structure_recognition_lines_wol as tsrlwol\n",
    "import Multi_Type_TD_TSR.google_colab.table_xml as txml\n",
    "import Multi_Type_TD_TSR.google_colab.table_ocr as tocr\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import random\n",
    "from detectron2.utils.logger import setup_logger\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607b136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create detectron config\n",
    "cfg = get_cfg()\n",
    "\n",
    "#set yaml\n",
    "cfg.merge_from_file('/Users/aifen/Desktop/All_X152.yaml')\n",
    "\n",
    "#set model weights\n",
    "cfg.MODEL.WEIGHTS = '/Users/aifen/Desktop/model_final.pth' # Set path model .pth\n",
    "\n",
    "predictor = DefaultPredictor(cfg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04880afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfFileReader\n",
    "import requests, io\n",
    "import gzip\n",
    "import requests\n",
    "import pdf2image\n",
    "import cv2\n",
    "import camelot\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735892ef",
   "metadata": {},
   "source": [
    "### Table Detection (Jermaine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc3a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if two rectangles overlap by using top left and bottom right coordinates\n",
    "def isoverlap(r1, r2):\n",
    "    y1 = r1[1]\n",
    "    x1 = r1[0]\n",
    "    h1 = r1[3]\n",
    "    w1 = r1[2]\n",
    "    \n",
    "    y2 = r2[1]\n",
    "    x2 = r2[0]\n",
    "    h2 = r2[3]\n",
    "    w2 = r2[2]\n",
    "    \n",
    "    if ((x1+w1)<x2 or (x2+w2)<x1 or (y1+h1)<y2 or (y2+h2)<y1):\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9265a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Discard overlapping tables detected\n",
    "def check_coord_overlap(table_coords):\n",
    "    \n",
    "    new_table_coords = []\n",
    "    \n",
    "    for i in range (len(table_coords)):\n",
    "        flag = True\n",
    "        if i == 0:\n",
    "            new_table_coords.append(table_coords[i])\n",
    "        else:\n",
    "            for j in range (len(new_table_coords)):\n",
    "                if isoverlap(table_coords[i], new_table_coords[j]):\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                new_table_coords.append(table_coords[i])\n",
    "    \n",
    "    return new_table_coords    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e2821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of keywords\n",
    "ESG_DICTIONARY = ['ghg emissions', 'scope 1', \n",
    "                'scope 2', 'scope 3', 'energy', \n",
    "                'paper', 'green bonds', 'renewable energy',\n",
    "                'water', 'carbon intensity', \n",
    "                'carbon emissions', 'waste', \n",
    "                'electricity', \n",
    "                'weighted average carbon intensity', 'WACI']\n",
    "\n",
    "# list of units\n",
    "ESG_UNITS = ['tonnes', 'tons', 'kWh', 'kilogram', 'kilowatt hour', \n",
    "           'gigajoules', 'GJ', 'litre', 'liter', 'CO2e', 'tCO', 't CO', 'MWh', \n",
    "           'megawatt hour', 'GWh', 'gigawatt hour',\n",
    "           'cubic metres', 'cm3', 'm3', 'per employee', 'ream', 'quire', 'sheet', 'bundle', 'bale']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b82d0b",
   "metadata": {},
   "source": [
    "### Table Extraction (Ai Fen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b846d1c",
   "metadata": {},
   "source": [
    "#### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe445bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_dimension(pdf_url):\n",
    "    response = requests.get(pdf_url)\n",
    "    with io.BytesIO(response.content) as open_pdf_file:\n",
    "        pdf = PdfFileReader(open_pdf_file, strict=False)\n",
    "        height = pdf.getPage(0).mediaBox.getHeight()\n",
    "        width = pdf.getPage(0).mediaBox.getWidth()\n",
    "    return height, width\n",
    "\n",
    "# https://stackoverflow.com/questions/51481200/convert-pdf-to-image-using-pdf-url-pdf2image\n",
    "# https://stackoverflow.com/questions/65180516/python-pdf2image-from-link-unable-to-get-page-count **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a2d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_and_dimension(pdf_url):\n",
    "    response = requests.get(pdf_url, stream=True, timeout=30)\n",
    "    # pdf = gzip.open(response.raw)\n",
    "    # images = pdf2image.convert_from_bytes(pdf.read())\n",
    "    images = pdf2image.convert_from_bytes(response.content, size=1000)\n",
    "    pg_1_img = images[0] # type=PIL.PpmImagePlugin.PpmImageFile\n",
    "    width, height = pg_1_img.size\n",
    "    return height, width, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaling_factor(pdf_height, pdf_width, img_height, img_width):\n",
    "    scaling_factor_height = img_height/pdf_height\n",
    "    scaling_factor_width = img_width/pdf_width\n",
    "    return scaling_factor_height, scaling_factor_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256aaf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_PIL_cv2(pdf_pil_img):\n",
    "    pdf_cv2_img = []\n",
    "    for pil_img in pdf_pil_img:\n",
    "        cv2_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)\n",
    "        pdf_cv2_img.append(cv2_img)\n",
    "    return pdf_cv2_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4306f1c4",
   "metadata": {},
   "source": [
    "#### Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up tables \n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def num_there(s):\n",
    "    return any(i.isdigit() for i in s)\n",
    "\n",
    "# list of units to be used for filtering - note: this is different from the ones under Table Detection section! \n",
    "UNITS = ['tonnes', 'tons', 'kWh', 'kilogram', 'kilowatt hour', \n",
    "           'gigajoules', 'GJ', 'litre', 'liter', 'CO2e', 'tCO', 't CO', 'MWh', \n",
    "           'megawatt hour', 'GWh', 'gigawatt hour',\n",
    "           'cubic metres', 'cm3', 'm3', 'per employee', 'ream', 'quire', 'sheet', 'bundle', 'bale', '%', 't']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ec6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return cleaned tbl and list of words \n",
    "def clean_tbl(tbl):\n",
    "    # replace subscript and newline \n",
    "    tbl = tbl.replace(r'(<s>).*(</s>)','',regex=True)\n",
    "    tbl = tbl.replace(r'\\n','',regex=True)\n",
    "    # convert 1st row to header \n",
    "    header_df = tbl.iloc[0] #grab the first row for the header\n",
    "    tbl = tbl[1:]\n",
    "    tbl.columns = header_df \n",
    "    # remove comma in numeric values \n",
    "    tbl = tbl.apply(lambda x: x.str.replace(',',''))\n",
    "    # remove brackets surrounding numeric metrics \n",
    "    tbl = tbl.replace(r\"\\((\\d+)\\)\", r\"\\1\", regex=True)\n",
    "    # loop through each cell and check if they are float/num or they are metrics with units \n",
    "    for row in range(tbl.shape[0]):\n",
    "        for col in range(1, tbl.shape[1]):\n",
    "            value = tbl.iloc[row, col]\n",
    "            if len(value.split()) > 3:\n",
    "                tbl.iloc[row,col] = np.nan\n",
    "            elif isfloat(value) or (any(substring in value for substring in UNITS) and num_there(value)):\n",
    "                continue \n",
    "            else:\n",
    "                tbl.iloc[row,col] = np.nan\n",
    "    # drop columns with > 80% NaN\n",
    "    tbl = tbl.loc[:, tbl.isnull().mean() < .8]\n",
    "    # drop rows with any NaN\n",
    "    tbl = tbl.dropna()\n",
    "    print('here1')\n",
    "    if (tbl.shape[1] == 1) or (tbl.shape[0] == 0): # if there's only 1 col left or 0 row left \n",
    "        return None, None \n",
    "    page_kw = ['page', 'Page', 'PAGE']\n",
    "    for s in page_kw:\n",
    "        if any(s in h for h in tbl.columns):\n",
    "            return None, None \n",
    "    print('here2')\n",
    "    first_column = tbl.iloc[:, 0] # get first column of tbl \n",
    "    num_of_nan = first_column.isnull().sum(axis = 0)\n",
    "    # large proportion of nan cells in 1st column\n",
    "    if num_of_nan/len(first_column) > 0.8:\n",
    "        return None, None\n",
    "    print('here3')\n",
    "    # no headers \n",
    "    headers =tbl.columns\n",
    "    if not(any(h for h in headers)):\n",
    "        return None, None \n",
    "    print('here4')\n",
    "    # list of words in df for relevance \n",
    "    words = pd.unique(tbl.values.ravel())\n",
    "    words = pd.unique([word for line in words for word in line.split()])\n",
    "    final_words = []\n",
    "    print('here5')\n",
    "    for s in ESG_DICTIONARY:\n",
    "        if any(s in word for word in words):\n",
    "            final_words.append(s) \n",
    "    print('here7')\n",
    "    return tbl, final_words "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19906f31",
   "metadata": {},
   "source": [
    "### Combined Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a9f51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract text-based and image-based tbl from individual page \n",
    "def extract_tbl_from_page(page_idx, pdf_cv2_img, scaling_factor_height, scaling_factor_width, img_height, url):\n",
    "    table_list, table_coords = table_detection.make_prediction(pdf_cv2_img[page_idx], predictor)\n",
    "    tbl_lst = []\n",
    "    keywords_lst = []\n",
    "    # img_lst = []\n",
    "    \n",
    "    table_coords = check_coord_overlap(table_coords) # newly added \n",
    "    \n",
    "    count = -1\n",
    "    # ---- start Table extraction ---- /recount from every page \n",
    "    # i = 0 \n",
    "    # ---- end Table extraction ----\n",
    "    for table_coord in table_coords:\n",
    "        count += 1\n",
    "        try: \n",
    "            x1 = table_coord[0]\n",
    "            y1 = table_coord[1]\n",
    "            x2 = table_coord[2] + table_coord[0]\n",
    "            y2 = table_coord[3] + table_coord[1]\n",
    "            \n",
    "            # extract detected table by coordinates (Jermaine's part)\n",
    "            page_img = pdf_cv2_img[page_idx]\n",
    "            page_img = page_img[y1:y2, x1:x2]\n",
    "            scale_percent = 150 # percent of original size\n",
    "            width = int(page_img.shape[1] * scale_percent / 100)\n",
    "            height = int(page_img.shape[0] * scale_percent / 100)\n",
    "            dim = (width, height)\n",
    "            # resize image\n",
    "            resized = cv2.resize(page_img, dim)\n",
    "            #cv2_imshow(resized)\n",
    "            text = pytesseract.image_to_string(resized)\n",
    "            \n",
    "            # if any keyword found in text in table, save image into output folder\n",
    "            if any(keyword in text.lower() for keyword in ESG_DICTIONARY) and any(unit in text for unit in ESG_UNITS):\n",
    "                print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "                print(\"RELEVANT IMAGE FOUND!, tbl_num is {0}\".format(count))\n",
    "                print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "                \n",
    "                # cv2 and pdf used 2 different coordinate systems, thus y1 and y2 need to be modified\n",
    "                y1 = img_height - y1\n",
    "                y2 = img_height - y2\n",
    "                \n",
    "                # scale by scaling factors\n",
    "                scaled_x1 = x1/scaling_factor_width\n",
    "                scaled_x2 = x2/scaling_factor_width\n",
    "                scaled_y1 = y1/scaling_factor_height\n",
    "                scaled_y2 = y2/scaling_factor_height\n",
    "                edge_tol = scaled_x2 - scaled_x1\n",
    "                coords = f\"{scaled_x1}, {scaled_y1}, {scaled_x2}, {scaled_y2}\"\n",
    "                \n",
    "                tbls_scaled = camelot.read_pdf(url, flavor='stream', edge_tol=edge_tol, pages=str(page_idx+1), flag_size=True, table_areas=[coords], split_text=True) # split_text=True\n",
    "                tbl_cleaned, ESG_keywords = clean_tbl(tbls_scaled[0].df)\n",
    "                # there is a valid table \n",
    "                \n",
    "                if tbl_cleaned is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "                    print(\"CLEANED TABLE OBTAINED!, tbl_num is {0}\".format(count))\n",
    "                    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "                    tbl_lst.append(tbl_cleaned)\n",
    "                    keywords_lst.append(ESG_keywords)\n",
    "                    # Table detection portion saving \n",
    "                    # --- start ---\n",
    "                    # output_path = f\"{copy_to_path}/PAGE{str(page_idx+1)}_IMAGE{str(i)}.jpg\"\n",
    "                    # cv2.imwrite(output_path, img)\n",
    "                    # i += 1\n",
    "                    # lst_imgs.append([\"(\"+str(y)+\":\"+str(y+h)+\", \"+str(x)+\":\"+str(x+w)+\")\", output_path])\n",
    "                    # --- end ---\n",
    "                \n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print('error on page {0}'.format(page_idx+1))\n",
    "            continue \n",
    "    \n",
    "    # return tbl_lst, keywords_lst, lst_imgs\n",
    "    return tbl_lst, keywords_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871cfef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a pdf_dict => key = page, value = lst of df (tables)\n",
    "# returns a keywords_dict => key=page, value = lst of lst (keywords) \n",
    "def extract_tbl_from_pdf(pdf_url, pages_to_look_for): \n",
    "    \n",
    "    pdf_dict = {}\n",
    "    keywords_dict = {}\n",
    "    # image_path_obj = {}\n",
    "    \n",
    "    # consistent to all pages in a pdf_url \n",
    "    print('getting pdf & img height, width...')\n",
    "    pdf_height, pdf_width = get_pdf_dimension(pdf_url) # original pdf height,width \n",
    "    img_height, img_width, pdf_pil_img = get_image_and_dimension(pdf_url) # original image height,width \n",
    "    scaling_factor_height, scaling_factor_width = get_scaling_factor(pdf_height, pdf_width, img_height, img_width)\n",
    "    print('retrieved pdf & img height, width')\n",
    "    \n",
    "    # convert PIL images to CV images\n",
    "    print('converting all pages to CV2 img...')\n",
    "    pdf_cv2_img = convert_PIL_cv2(pdf_pil_img)\n",
    "    print ('converted all pages to CV2 img')\n",
    "    \n",
    "    # pdf_cv2_img = images of all pages in a pdf \n",
    "    print('looping through each page...')\n",
    "    for page_no in pages_to_look_for:\n",
    "        print('retrieving from page {0}'.format(page_no))\n",
    "        page_idx = int(page_no) - 1\n",
    "        tbl_lst, keywords_lst = extract_tbl_from_page(page_idx, pdf_cv2_img, scaling_factor_height, scaling_factor_width, img_height, pdf_url)\n",
    "        # tbl_lst, keywords_lst, img_lst = extract_tbl_from_page(page_idx, pdf_cv2_img, scaling_factor_height, scaling_factor_width, img_height, pdf_url)\n",
    "        pdf_dict[page_no] = tbl_lst\n",
    "        keywords_dict[page_no] = keywords_lst\n",
    "        # image_path_obj[page_no] = img_lst\n",
    "    \n",
    "    # return pdf_dict, keywords_dict, image_path_obj\n",
    "    return pdf_dict, keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b1d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_JSON(file_path):\n",
    "    \n",
    "    f = open(file_path,)\n",
    "    data = json.load(f)\n",
    "    \n",
    "    json_lst = []\n",
    "    keywords_lst = []\n",
    "    count = 1\n",
    "    \n",
    "    # json_lst_img = []\n",
    "    \n",
    "    for report in data:     \n",
    "        print('--------------------------NEW REPORT {0}--------------------------'.format(count))\n",
    "        count += 1\n",
    "        \n",
    "        # basic information\n",
    "        company = report['company']\n",
    "        year = report['year']\n",
    "        pdf_url = report['url']\n",
    "        \n",
    "        # create dictionary for report \n",
    "        report_dict = {}\n",
    "        report_dict['company'] = company\n",
    "        report_dict['year'] = year\n",
    "        report_dict['pdf_url'] = pdf_url\n",
    "        \n",
    "        # create dictionary for keywords\n",
    "        kw_dict = {}\n",
    "        kw_dict['company'] = company\n",
    "        kw_dict['year'] = year\n",
    "        kw_dict['pdf_url'] = pdf_url\n",
    "        \n",
    "        # json_obj = {}\n",
    "        # json_obj['company'] = company\n",
    "        # json_obj['year'] = year\n",
    "        # json_obj['pdf_url'] = pdf_url\n",
    "        # path = output_path + company + '_' + year\n",
    "        # os.mkdir(path)\n",
    "        # print(f\"Detection for Report: {company}_{year}\")\n",
    "        \n",
    "        # relevant pages for ESG info extraction\n",
    "        pages_to_look_for = []\n",
    "        for page in report['filtered_report_tables_direct']:\n",
    "            pages_to_look_for.append(page)\n",
    "            \n",
    "        for page in report['filtered_report_tables_indirect']:\n",
    "            pages_to_look_for.append(page)\n",
    "            \n",
    "        # retrieve pdf via link - if link is not valid, go to next company \n",
    "        if \".pdf\" not in pdf_url:\n",
    "            print(\"{0}'s URL is not a PDF. Year is {1}\".format(company, year))\n",
    "            continue \n",
    "            \n",
    "        else:\n",
    "            # extract tbl from relevant pages in a pdf \n",
    "            try:\n",
    "                print('calling extract_tbl_from_pdf')\n",
    "                report_dict['tbl_pages'], kw_dict['tbl_pages'] = extract_tbl_from_pdf(pdf_url, pages_to_look_for) # returns a dict \n",
    "                # report_dict['tbl_pages'], kw_dict['tbl_pages'], json_obj['images_path']= extract_tbl_from_pdf(pdf_url, pages_to_look_for) \n",
    "                json_lst.append(report_dict)\n",
    "                keywords_lst.append(kw_dict)\n",
    "                print('Successfull for {0}, {1}'.format(company, year))\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error occurred in table_extraction/ Request failed\")\n",
    "                report_dict['tbl_pages'] = []\n",
    "                \n",
    "            # json_lst_img.append(json_obj)\n",
    "    \n",
    "    # return json_lst, keywords_lst, json_lst_img\n",
    "    return json_lst, keywords_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35767292",
   "metadata": {},
   "source": [
    "### Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40945157",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_asian_banks, keywords_asian_banks = open_JSON('/Users/aifen/Desktop/output_capstone/preprocessed/all_asian_banks_preprocessed_vfinal.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl_asian_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa72c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving of df \n",
    "import pickle\n",
    "with open('/Users/aifen/Desktop/output_capstone/Pickle_v2/tbl_asian_banks.pickle', 'wb') as tbl_asian_banks_pickle:\n",
    "    pickle.dump(tbl_asian_banks, tbl_asian_banks_pickle, protocol=pickle.HIGHEST_PROTOCOL)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure it has been saved, this is just for checking \n",
    "loaded_tbl_asian_banks = pd.read_pickle(r'/Users/aifen/Desktop/output_capstone/Pickle_v2/tbl_asian_banks.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9578326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving of keywords \n",
    "import json\n",
    "with open('/Users/aifen/Desktop/output_capstone/JSON_v2/text_asian_banks.json', 'w') as fout:\n",
    "    json.dump(keywords_asian_banks, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving of images - Jermaine's portion\n",
    "# with open('asian_banks_output.json', 'w') as f:\n",
    "#     json.dump(json_lst_img, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
