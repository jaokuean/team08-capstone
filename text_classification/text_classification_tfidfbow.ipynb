{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000fb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing import * \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../data/all_labelled_17Oct.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1080133f",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['index', 'sentence', 'relevance', 'carbon_class']\n",
    "df1['cleaned_sentence'] = df1['sentence'].apply(clean_sentence)\n",
    "df1 = df1[df1['carbon_class'].notnull()]\n",
    "df1 = df1.astype({'carbon_class':int})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b6799f",
   "metadata": {},
   "source": [
    "# Split labelled set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = \\\n",
    "              np.split(df1.sample(frac=1, random_state=4103), \n",
    "                       [int(.6*len(df1)), int(.8*len(df1))])\n",
    "trainval =pd.concat([train, val])# Split labelled set\n",
    "labels = [train.carbon_class, val.carbon_class, test.carbon_class, trainval.carbon_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ef49f",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_params = {\n",
    "    \"analyzer\": [\"word\"],\n",
    "    \"lowercase\": [True],\n",
    "    \"ngram_range\": [(1,1), (1,2), (1,3)],\n",
    "    \"max_df\": [0.25, 0.5, 1.0],\n",
    "    \"min_df\": [1, 10, 20]\n",
    "}\n",
    "vect_paramgrid = list(ParameterGrid(vect_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2792bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_methods = {'type': ['bow', 'tfidf'],'processing': ['clean','raw']}\n",
    "vect_methods_paramgrid = list(ParameterGrid(vect_methods))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ecc742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "logreg_params = { \"C\": [0.1, 0.5, 1.0, 5], \n",
    "                 \"solver\": [\"lbfgs\", \"newton-cg\"], \n",
    "                 \"penalty\": [\"l2\", \"none\"],\n",
    "                 \"class_weight\": [\"balanced\", None]}\n",
    "logreg_paramgrid = list(ParameterGrid(logreg_params))\n",
    "\n",
    "# naive bayes\n",
    "nb_params = {\"alpha\": [0, 0.001, 0.01, 0.1, 0.25, 0.5, 1]}\n",
    "nb_paramgrid = list(ParameterGrid(nb_params))\n",
    "\n",
    "# svm\n",
    "svm_params = { \"C\": [0.1, 0.5, 1, 5],\n",
    "    \"kernel\": [\"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"gamma\": [\"scale\", \"auto\"],\n",
    "    \"class_weight\": [\"balanced\", None] \n",
    "}\n",
    "\n",
    "svm_paramgrid = list(ParameterGrid(svm_params))\n",
    "\n",
    "# rf\n",
    "rf_params = [\n",
    "    {\n",
    "        \"criterion\": [\"gini\", \"entropy\"],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"class_weight\": [\"balanced\", \"balanced_subsample\", None],\n",
    "        \"max_features\": [\"auto\",\"log2\"],\n",
    "        \"min_samples_leaf\": [1, 2, 4]\n",
    "    }\n",
    "]\n",
    "\n",
    "rf_paramgrid = list(ParameterGrid(rf_params))\n",
    "\n",
    "# dummy classifier\n",
    "dummy_params = { \"strategy\": [\"prior\"] }\n",
    "dummy_paramgrid = list(ParameterGrid(dummy_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_params = {'iterations': [50, 100, 200],\n",
    "             'depth': [1,2,5],\n",
    "             'learning_rate': [0.01, 0.1, 0.5, 1]}\n",
    "cb_paramgrid = list(ParameterGrid(cb_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2ecb32",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ade87a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_smote(X,y):\n",
    "    smote = SMOTE(random_state = 4103)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a67b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_helper(vect, sentence_version):\n",
    "    vec_train = vect.fit_transform(train[sentence_version])\n",
    "    vec_val = vect.transform(val[sentence_version])\n",
    "    vec_test = vect.transform(test[sentence_version])\n",
    "    vec_trainval = vect.transform(trainval[sentence_version])\n",
    "    \n",
    "    vec_train_oversampled = oversample_smote(vec_train, labels[0])\n",
    "    vec_trainval_oversampled = oversample_smote(vec_trainval, labels[3])\n",
    "    return vec_train_oversampled, vec_val, vec_test, vec_trainval_oversampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7dcc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_dataset(vect_param):\n",
    "    # bag of words\n",
    "    \n",
    "    # raw\n",
    "    bow = CountVectorizer(**vect_param)\n",
    "    bow_train_oversampled, bow_val, bow_test, bow_trainval_oversampled = vectorize_helper(bow, 'sentence')\n",
    "\n",
    "    # cleaned\n",
    "    bow = CountVectorizer(**vect_param)\n",
    "    bow_train_clean_oversampled, bow_clean_val, bow_clean_test, bow_trainval_clean_oversampled = vectorize_helper(bow, 'cleaned_sentence')\n",
    "    \n",
    "    \n",
    "    # tfidf\n",
    "    \n",
    "    # raw\n",
    "    tfidf = TfidfVectorizer(**vect_param)\n",
    "    tfidf_train_oversampled, tfidf_val, tfidf_test, tfidf_trainval_oversampled = vectorize_helper(tfidf, 'sentence')\n",
    "    \n",
    "    # cleaned\n",
    "    tfidf = TfidfVectorizer(**vect_param)    \n",
    "    tfidf_train_clean_oversampled, tfidf_clean_val, tfidf_clean_test, tfidf_trainval_clean_oversampled = vectorize_helper(tfidf, 'cleaned_sentence')\n",
    "\n",
    "    return {'bow': {'clean': [bow_train_clean_oversampled, bow_clean_val, bow_clean_test, bow_trainval_clean_oversampled],\n",
    "                    'raw': [bow_train_oversampled, bow_val, bow_test, bow_trainval_oversampled]},\n",
    "            'tfidf': {'clean': [tfidf_train_clean_oversampled, tfidf_clean_val, tfidf_clean_test, tfidf_trainval_clean_oversampled],\n",
    "                     'raw':[tfidf_train_oversampled, tfidf_val, tfidf_test, tfidf_trainval_oversampled]}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c11cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparam_search(model, model_function, model_grid):\n",
    "    ind = 0 \n",
    "    gridsearch_results = []\n",
    "    for vect_param in tqdm(vect_paramgrid):\n",
    "        dataset = vectorize_dataset(vect_param)\n",
    "        for vect_choice in vect_methods_paramgrid:\n",
    "            vect_type  = vect_choice['type']\n",
    "            sentence_proc = vect_choice['processing']\n",
    "            train_hp = dataset[vect_type][sentence_proc][0][0]\n",
    "            val_hp = dataset[vect_type][sentence_proc][1]\n",
    "            test_hp = dataset[vect_type][sentence_proc][2]\n",
    "            trainval_hp = dataset[vect_type][sentence_proc][3][0]\n",
    "\n",
    "            train_label = dataset[vect_type][sentence_proc][0][1]\n",
    "            val_label = labels[1]\n",
    "            test_label = labels[2]\n",
    "            trainval_label = dataset[vect_type][sentence_proc][3][1]\n",
    "\n",
    "            for model_param in model_grid:\n",
    "                # fit model on train set\n",
    "                model = model_function(**model_param)\n",
    "                model.fit(train_hp, train_label)\n",
    "                val_pred = model.predict(val_hp)\n",
    "\n",
    "                # scoring\n",
    "                val_metrics = classification_report(val_label, val_pred, output_dict=True)\n",
    "                val_accuracy = val_metrics[\"accuracy\"]\n",
    "                val_f1_weighted = val_metrics[\"weighted avg\"][\"f1-score\"]\n",
    "                val_f1_zero = val_metrics[\"0\"][\"f1-score\"]\n",
    "                val_f1_one = val_metrics[\"1\"][\"f1-score\"]\n",
    "                val_f1_two = val_metrics[\"2\"][\"f1-score\"]\n",
    "                val_f1_three = val_metrics[\"3\"][\"f1-score\"]\n",
    "                val_f1_four = val_metrics[\"4\"][\"f1-score\"]\n",
    "                \n",
    "                # fit model on trainval set\n",
    "                model = model_function(**model_param)\n",
    "                model.fit(trainval_hp, trainval_label)\n",
    "                test_pred = model.predict(test_hp)\n",
    "\n",
    "                # scoring\n",
    "                test_metrics = classification_report(test_label, test_pred, output_dict=True)\n",
    "                test_accuracy = test_metrics[\"accuracy\"]\n",
    "                test_f1_weighted = test_metrics[\"weighted avg\"][\"f1-score\"]\n",
    "                test_f1_zero = test_metrics[\"0\"][\"f1-score\"]\n",
    "                test_f1_one = test_metrics[\"1\"][\"f1-score\"]\n",
    "                test_f1_two = test_metrics[\"2\"][\"f1-score\"]\n",
    "                test_f1_three = test_metrics[\"3\"][\"f1-score\"]\n",
    "                test_f1_four = test_metrics[\"4\"][\"f1-score\"]\n",
    "\n",
    "\n",
    "                results = {\"model\": model}\n",
    "                results.update(vect_param)\n",
    "                results.update(vect_choice)\n",
    "                results.update(model_param)\n",
    "                results.update({\"val_f1_weighted\": val_f1_weighted,  \n",
    "                                \"val_f1_zero\": val_f1_zero,\n",
    "                                \"val_f1_one\": val_f1_one,\n",
    "                                \"val_f1_two\": val_f1_two,\n",
    "                                \"val_f1_three\": val_f1_three,\n",
    "                                \"val_f1_four\": val_f1_four,\n",
    "                                \"val_accuracy\": val_accuracy})\n",
    "                results.update({\"test_f1_weighted\": test_f1_weighted, \n",
    "                                \"test_f1_zero\": test_f1_zero,\n",
    "                                \"test_f1_one\": test_f1_one,\n",
    "                                \"test_f1_two\": test_f1_two,\n",
    "                                \"test_f1_three\": test_f1_three,\n",
    "                                \"test_f1_four\": test_f1_four,\n",
    "                                \"test_accuracy\": test_accuracy})\n",
    "                gridsearch_results.append(results)\n",
    "                ind += 1\n",
    "    final_results = pd.DataFrame.from_records(gridsearch_results)\n",
    "    final_results = final_results.sort_values(by=[\"val_f1_weighted\", \"test_f1_weighted\"], ascending=False)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7658fa",
   "metadata": {},
   "source": [
    "# Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f98821",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_lr_results = hyperparam_search(\"log_reg\", LogisticRegression, logreg_paramgrid)\n",
    "final_lr_results.to_csv(\"model_results/bowtfidf/logreg_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd076ca",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4e3398",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_nb_results = hyperparam_search(\"nb\", MultinomialNB, nb_paramgrid)\n",
    "final_nb_results.to_csv(\"model_results/bowtfidf/nb_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8c552c",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d91fa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svm_results = hyperparam_search(\"svm\", SVC, svm_paramgrid)\n",
    "final_svm_results.to_csv(\"model_results/bowtfidf/svm_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2382b69",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d86e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_rf_results = hyperparam_search(\"rf\", RandomForestClassifier, rf_paramgrid)\n",
    "final_rf_results.to_csv(\"model_results/bowtfidf/rf_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf0846b",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1282f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cb_results = hyperparam_search(\"catboost\", CatBoostClassifier, cb_paramgrid)\n",
    "final_cb_results.to_csv(\"model_results/bowtfidf/cb_smote.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae17cae",
   "metadata": {},
   "source": [
    "# Base Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcac8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dummy_results = hyperparam_search(\"dummy\", DummyClassifier, dummy_paramgrid)\n",
    "final_dummy_results.to_csv(\"model_results/bowtfidf/dummy.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python388jvsc74a57bd0008e83f9660cc2c6b74ec749cb321b12384d3e1ed2527a0588d1b73db62f72fc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
